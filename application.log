2023-10-07 16:22:38,791 - Ingest - WARNING - Ingesting the file
2023-10-07 16:22:38,804 - UDF - WARNING - Calling the user defined function
2023-10-07 16:22:38,807 - Dataprocessing - WARNING - starting the data processing module
2023-10-07 16:22:38,808 - Dataprocessing - WARNING - creating the class method for data standardization -cleaning, transformations etc
2023-10-07 16:22:38,808 - Dataprocessing - WARNING - initalizing the txn count module by city
2023-10-07 16:22:38,811 - root - INFO - I am in the main method
2023-10-07 16:22:38,811 - root - INFO - calling the sparkobject
2023-10-07 16:22:38,811 - SparkSession - INFO - get spark obj method started
2023-10-07 16:22:38,812 - SparkSession - INFO - master is local
2023-10-07 16:22:59,580 - SparkSession - INFO - Spark obj created
2023-10-07 16:22:59,606 - root - INFO - validating sparkobj
2023-10-07 16:22:59,606 - Validate - WARNING - Started the gcd module
2023-10-07 16:23:07,037 - Validate - WARNING - Validation done!!!
2023-10-07 16:23:07,037 - root - INFO -  invoking ingest module for olap module
2023-10-07 16:23:11,864 - root - INFO - read the file from path C:\Users\Manoranjan\PycharmProjects\pythonProject1\source\olap
2023-10-07 16:23:11,864 - root - INFO - calling count from validate method
2023-10-07 16:23:12,828 - root - INFO - got the count sucessfully
2023-10-07 16:23:12,829 - root - INFO -  invoking ingest module for oltp module
2023-10-07 16:23:14,190 - root - INFO - read the file from path C:\Users\Manoranjan\PycharmProjects\pythonProject1\source\oltp
2023-10-07 16:23:14,190 - root - INFO - calling count from validate method
2023-10-07 16:23:15,912 - root - INFO - got the count sucessfully
2023-10-07 16:23:15,912 - root - INFO - invoking the data processing -data clean transform module
2023-10-07 16:23:15,912 - root - INFO - invoking the  select col method in clean transform module
2023-10-07 16:23:15,913 - Dataprocessing - WARNING - creating the method col_sel inside main class
2023-10-07 16:23:15,913 - Dataprocessing - WARNING - selecting the requried columns from df1 dataset
2023-10-07 16:23:15,997 - Dataprocessing - WARNING - selected the requried columns from df1 dataset
2023-10-07 16:23:15,998 - Dataprocessing - WARNING - selecting the requried columns from df2 dataset
2023-10-07 16:23:16,231 - Dataprocessing - WARNING - selected the requried columns from df2 dataset
2023-10-07 16:23:16,231 - Dataprocessing - WARNING - excecuted the module col sel sucessfully
2023-10-07 16:23:16,231 - root - INFO - Executed the select col method sucessfully
2023-10-07 16:23:47,722 - root - INFO - printing the count of city and presc
2023-10-07 16:24:11,763 - root - INFO - invoking the distinct prescriber count by module for city
2023-10-07 16:24:11,763 - Dataprocessing - WARNING - invoking distinct_presc module 
2023-10-07 16:24:11,829 - Dataprocessing - WARNING - distinct_presc module executed sucessfully
2023-10-07 16:24:11,829 - root - INFO - printing the distinct prescriber count by module for city
2023-10-07 16:24:26,370 - root - INFO - invoking the distinct txn count by module for city
2023-10-07 16:24:26,371 - Dataprocessing - WARNING - initialzing the txn module
2023-10-07 16:24:26,690 - Dataprocessing - WARNING - module txn_count executed sucessfully
2023-10-07 16:25:10,448 - root - INFO - printing the distinct txn count by module for city
2023-10-07 16:25:10,448 - root - INFO - invoking the distinct prescriber count by module for city
2023-10-07 16:25:10,449 - Dataprocessing - WARNING - invoking distinct_presc module 
2023-10-07 16:25:10,500 - Dataprocessing - WARNING - distinct_presc module executed sucessfully
2023-10-07 16:25:10,501 - root - INFO - printing the distinct prescriber count by module for city
2023-10-07 16:25:20,377 - root - INFO - invoking the distinct txn count by module for city
2023-10-07 16:25:20,377 - Dataprocessing - WARNING - initialzing the txn module
2023-10-07 16:25:20,460 - Dataprocessing - WARNING - module txn_count executed sucessfully
2023-10-07 16:25:58,181 - root - INFO - printing the distinct txn count by module for city
2023-10-07 16:25:58,181 - root - INFO - invoking the pres_city_only
2023-10-07 16:25:58,182 - Dataprocessing - WARNING - invoking pres_city_module
2023-10-07 16:25:58,182 - Dataprocessing - WARNING - applying the logic to select only data in pres if it has city assigned in dim
2023-10-07 16:25:58,252 - Dataprocessing - WARNING - logic of pres_city_only module executed sucessfully
2023-10-07 16:25:58,253 - Dataprocessing - WARNING - Module pres_city executed sucessfully
2023-10-07 16:26:23,630 - root - INFO - printing the result of pres_city_only
2023-10-07 16:26:23,630 - root - INFO - invoking the zip size module
2023-10-07 16:26:23,733 - Dataprocessing - WARNING - calculated the length sucessfully
2023-10-07 16:26:36,238 - root - ERROR - An error occured while calling the main function, please check the trace ----An error occurred while calling o210.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 69.0 failed 1 times, most recent failure: Lost task 0.0 in stage 69.0 (TID 58) (192.168.1.37 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.
	at org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:54)
	at org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.SocketTimeoutException: Accept timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)
	at java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)
	at java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)
	at java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)
	at java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)
	at java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)
	at java.base/java.net.ServerSocket.accept(ServerSocket.java:543)
	at org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)
	... 27 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:530)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:374)
	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:402)
	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:374)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:280)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:315)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.spark.SparkException: Python worker failed to connect back.
	at org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:54)
	at org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:131)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	... 1 more
Caused by: java.net.SocketTimeoutException: Accept timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)
	at java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)
	at java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)
	at java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)
	at java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)
	at java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)
	at java.base/java.net.ServerSocket.accept(ServerSocket.java:543)
	at org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)
	... 27 more

2023-10-07 16:32:20,526 - Ingest - WARNING - Ingesting the file
2023-10-07 16:32:20,531 - UDF - WARNING - Calling the user defined function
2023-10-07 16:32:20,533 - Dataprocessing - WARNING - starting the data processing module
2023-10-07 16:32:20,533 - Dataprocessing - WARNING - creating the class method for data standardization -cleaning, transformations etc
2023-10-07 16:32:20,533 - Dataprocessing - WARNING - initalizing the txn count module by city
2023-10-07 16:32:20,535 - root - INFO - I am in the main method
2023-10-07 16:32:20,535 - root - INFO - calling the sparkobject
2023-10-07 16:32:20,535 - SparkSession - INFO - get spark obj method started
2023-10-07 16:32:20,535 - SparkSession - INFO - master is local
2023-10-07 16:32:26,447 - SparkSession - INFO - Spark obj created
2023-10-07 16:32:26,450 - root - INFO - validating sparkobj
2023-10-07 16:32:26,451 - Validate - WARNING - Started the gcd module
2023-10-07 16:32:33,641 - Validate - WARNING - Validation done!!!
2023-10-07 16:32:33,641 - root - INFO -  invoking ingest module for olap module
2023-10-07 16:32:38,310 - root - INFO - read the file from path C:\Users\Manoranjan\PycharmProjects\pythonProject1\source\olap
2023-10-07 16:32:38,310 - root - INFO - calling count from validate method
2023-10-07 16:32:39,402 - root - INFO - got the count sucessfully
2023-10-07 16:32:39,402 - root - INFO -  invoking ingest module for oltp module
2023-10-07 16:32:40,867 - root - INFO - read the file from path C:\Users\Manoranjan\PycharmProjects\pythonProject1\source\oltp
2023-10-07 16:32:40,867 - root - INFO - calling count from validate method
2023-10-07 16:32:42,500 - root - INFO - got the count sucessfully
2023-10-07 16:32:42,501 - root - INFO - invoking the data processing -data clean transform module
2023-10-07 16:32:42,501 - root - INFO - invoking the  select col method in clean transform module
2023-10-07 16:32:42,501 - Dataprocessing - WARNING - creating the method col_sel inside main class
2023-10-07 16:32:42,501 - Dataprocessing - WARNING - selecting the requried columns from df1 dataset
2023-10-07 16:32:42,572 - Dataprocessing - WARNING - selected the requried columns from df1 dataset
2023-10-07 16:32:42,573 - Dataprocessing - WARNING - selecting the requried columns from df2 dataset
2023-10-07 16:32:42,803 - Dataprocessing - WARNING - selected the requried columns from df2 dataset
2023-10-07 16:32:42,803 - Dataprocessing - WARNING - excecuted the module col sel sucessfully
2023-10-07 16:32:42,803 - root - INFO - Executed the select col method sucessfully
2023-10-07 16:33:11,124 - root - INFO - printing the count of city and presc
2023-10-07 16:33:33,013 - root - INFO - invoking the distinct prescriber count by module for city
2023-10-07 16:33:33,013 - Dataprocessing - WARNING - invoking distinct_presc module 
2023-10-07 16:33:33,076 - Dataprocessing - WARNING - distinct_presc module executed sucessfully
2023-10-07 16:33:33,076 - root - INFO - printing the distinct prescriber count by module for city
2023-10-07 16:33:43,555 - root - INFO - invoking the distinct txn count by module for city
2023-10-07 16:33:43,555 - Dataprocessing - WARNING - initialzing the txn module
2023-10-07 16:33:43,725 - Dataprocessing - WARNING - module txn_count executed sucessfully
2023-10-07 16:34:20,266 - root - INFO - printing the distinct txn count by module for city
2023-10-07 16:34:20,266 - root - INFO - invoking the distinct prescriber count by module for city
2023-10-07 16:34:20,267 - Dataprocessing - WARNING - invoking distinct_presc module 
2023-10-07 16:34:20,325 - Dataprocessing - WARNING - distinct_presc module executed sucessfully
2023-10-07 16:34:20,326 - root - INFO - printing the distinct prescriber count by module for city
2023-10-07 16:34:30,065 - root - INFO - invoking the distinct txn count by module for city
2023-10-07 16:34:30,065 - Dataprocessing - WARNING - initialzing the txn module
2023-10-07 16:34:30,149 - Dataprocessing - WARNING - module txn_count executed sucessfully
2023-10-07 16:35:04,077 - root - INFO - printing the distinct txn count by module for city
2023-10-07 16:35:04,077 - root - INFO - invoking the pres_city_only
2023-10-07 16:35:04,078 - Dataprocessing - WARNING - invoking pres_city_module
2023-10-07 16:35:04,078 - Dataprocessing - WARNING - applying the logic to select only data in pres if it has city assigned in dim
2023-10-07 16:35:04,128 - Dataprocessing - WARNING - logic of pres_city_only module executed sucessfully
2023-10-07 16:35:04,128 - Dataprocessing - WARNING - Module pres_city executed sucessfully
2023-10-07 16:35:26,392 - root - INFO - printing the result of pres_city_only
2023-10-07 16:35:26,392 - root - INFO - invoking the zip size module
2023-10-07 16:35:26,440 - Dataprocessing - WARNING - calculated the length sucessfully
2023-10-07 16:35:26,440 - root - INFO - printing the result of df_city_size
2023-10-07 16:35:26,440 - root - INFO - invoking the top txn count module
2023-10-07 16:35:26,440 - Dataprocessing - WARNING - invoking the top_txn_state module 
2023-10-07 16:35:26,551 - Dataprocessing - WARNING - top txn module executed sucessfully
2023-10-07 16:36:24,024 - root - INFO - Application executed
2023-10-07 16:37:00,119 - Ingest - WARNING - Ingesting the file
2023-10-07 16:37:00,122 - UDF - WARNING - Calling the user defined function
2023-10-07 16:37:00,123 - Dataprocessing - WARNING - starting the data processing module
2023-10-07 16:37:00,123 - Dataprocessing - WARNING - creating the class method for data standardization -cleaning, transformations etc
2023-10-07 16:37:00,124 - Dataprocessing - WARNING - initalizing the txn count module by city
2023-10-07 16:37:00,125 - root - INFO - I am in the main method
2023-10-07 16:37:00,125 - root - INFO - calling the sparkobject
2023-10-07 16:37:00,125 - SparkSession - INFO - get spark obj method started
2023-10-07 16:37:00,125 - SparkSession - INFO - master is local
2023-10-07 16:37:05,818 - SparkSession - INFO - Spark obj created
2023-10-07 16:37:05,821 - root - INFO - validating sparkobj
2023-10-07 16:37:05,821 - Validate - WARNING - Started the gcd module
2023-10-07 16:37:13,006 - Validate - WARNING - Validation done!!!
2023-10-07 16:37:13,006 - root - INFO -  invoking ingest module for olap module
2023-10-07 16:37:17,731 - root - INFO - read the file from path C:\Users\Manoranjan\PycharmProjects\pythonProject1\source\olap
2023-10-07 16:37:17,731 - root - INFO - calling count from validate method
2023-10-07 16:37:18,757 - root - INFO - got the count sucessfully
2023-10-07 16:37:18,757 - root - INFO -  invoking ingest module for oltp module
2023-10-07 16:37:20,271 - root - INFO - read the file from path C:\Users\Manoranjan\PycharmProjects\pythonProject1\source\oltp
2023-10-07 16:37:20,271 - root - INFO - calling count from validate method
2023-10-07 16:37:21,928 - root - INFO - got the count sucessfully
2023-10-07 16:37:21,928 - root - INFO - invoking the data processing -data clean transform module
2023-10-07 16:37:21,928 - root - INFO - invoking the  select col method in clean transform module
2023-10-07 16:37:21,929 - Dataprocessing - WARNING - creating the method col_sel inside main class
2023-10-07 16:37:21,929 - Dataprocessing - WARNING - selecting the requried columns from df1 dataset
2023-10-07 16:37:22,012 - Dataprocessing - WARNING - selected the requried columns from df1 dataset
2023-10-07 16:37:22,012 - Dataprocessing - WARNING - selecting the requried columns from df2 dataset
2023-10-07 16:37:22,267 - Dataprocessing - WARNING - selected the requried columns from df2 dataset
2023-10-07 16:37:22,268 - Dataprocessing - WARNING - excecuted the module col sel sucessfully
2023-10-07 16:37:22,268 - root - INFO - Executed the select col method sucessfully
2023-10-07 16:37:50,169 - root - INFO - printing the count of city and presc
2023-10-07 16:38:11,854 - root - INFO - invoking the distinct prescriber count by module for city
2023-10-07 16:38:11,854 - Dataprocessing - WARNING - invoking distinct_presc module 
2023-10-07 16:38:11,946 - Dataprocessing - WARNING - distinct_presc module executed sucessfully
2023-10-07 16:38:11,946 - root - INFO - printing the distinct prescriber count by module for city
2023-10-07 16:38:22,736 - root - INFO - invoking the distinct txn count by module for city
2023-10-07 16:38:22,737 - Dataprocessing - WARNING - initialzing the txn module
2023-10-07 16:38:22,927 - Dataprocessing - WARNING - module txn_count executed sucessfully
2023-10-07 16:38:59,177 - root - INFO - printing the distinct txn count by module for city
2023-10-07 16:38:59,177 - root - INFO - invoking the distinct prescriber count by module for city
2023-10-07 16:38:59,178 - Dataprocessing - WARNING - invoking distinct_presc module 
2023-10-07 16:38:59,229 - Dataprocessing - WARNING - distinct_presc module executed sucessfully
2023-10-07 16:38:59,230 - root - INFO - printing the distinct prescriber count by module for city
2023-10-07 16:39:08,677 - root - INFO - invoking the distinct txn count by module for city
2023-10-07 16:39:08,677 - Dataprocessing - WARNING - initialzing the txn module
2023-10-07 16:39:08,769 - Dataprocessing - WARNING - module txn_count executed sucessfully
2023-10-07 16:39:42,772 - root - INFO - printing the distinct txn count by module for city
2023-10-07 16:39:42,772 - root - INFO - invoking the pres_city_only
2023-10-07 16:39:42,773 - Dataprocessing - WARNING - invoking pres_city_module
2023-10-07 16:39:42,773 - Dataprocessing - WARNING - applying the logic to select only data in pres if it has city assigned in dim
2023-10-07 16:39:42,822 - Dataprocessing - WARNING - logic of pres_city_only module executed sucessfully
2023-10-07 16:39:42,822 - Dataprocessing - WARNING - Module pres_city executed sucessfully
2023-10-07 16:40:04,895 - root - INFO - printing the result of pres_city_only
2023-10-07 16:40:04,895 - root - INFO - invoking the zip size module
2023-10-07 16:40:04,952 - Dataprocessing - WARNING - calculated the length sucessfully
2023-10-07 16:40:04,952 - root - INFO - printing the result of df_city_size
2023-10-07 16:40:04,952 - root - INFO - invoking the top txn count module
2023-10-07 16:40:04,952 - Dataprocessing - WARNING - invoking the top_txn_state module 
2023-10-07 16:40:05,068 - Dataprocessing - WARNING - top txn module executed sucessfully
2023-10-07 16:42:04,203 - root - ERROR - An error occured while calling the main function, please check the trace ----An error occurred while calling o239.save.
: java.lang.UnsatisfiedLinkError: 'boolean org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(java.lang.String, int)'
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:275)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)
	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:374)
	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:402)
	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:374)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:1583)

